{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9398fe9e",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7b1a8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "##run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db88c264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "##run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4f0fbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4304705",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "vocab_size = 10000\n",
    "embedding_dim = 16\n",
    "max_length = 100\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<OOV>\"\n",
    "#run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a6eff4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   Text  Label\n",
      "0                              Wow... Loved this place.      1\n",
      "1                                    Crust is not good.      0\n",
      "2             Not tasty and the texture was just nasty.      0\n",
      "3     Stopped by during the late May bank holiday of...      1\n",
      "4     The selection on the menu was great and so wer...      1\n",
      "...                                                 ...    ...\n",
      "2743  The screen does get smudged easily because it ...      0\n",
      "2744  What a piece of junk.. I lose more calls on th...      0\n",
      "2745                       Item Does Not Match Picture.      0\n",
      "2746  The only thing that disappoint me is the infra...      0\n",
      "2747  You can not answer calls with the unit, never ...      0\n",
      "\n",
      "[2748 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OhniEhye\\AppData\\Local\\Temp\\ipykernel_9240\\2542106722.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = data.append(data2, ignore_index=True)\n",
      "C:\\Users\\OhniEhye\\AppData\\Local\\Temp\\ipykernel_9240\\2542106722.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(data3, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(r\"Dataset/yelp_labelled.txt\", delimiter='\\t', header=None)\n",
    "data2 = pd.read_csv(r\"Dataset/imdb_labelled.txt\", delimiter='\\t', header=None)\n",
    "data3 = pd.read_csv(r\"Dataset/amazon_cells_labelled.txt\", delimiter='\\t', header=None)\n",
    "\n",
    "data.columns = [\"Text\", \"Label\"]\n",
    "data2.columns = [\"Text\", \"Label\"]\n",
    "data3.columns = [\"Text\", \"Label\"]\n",
    "\n",
    "df = data.append(data2, ignore_index=True)\n",
    "df = df.append(data3, ignore_index=True)\n",
    "\n",
    "print(df)\n",
    "\n",
    "#run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f0bb5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "sentences = df.Text\n",
    "\n",
    "labels = []\n",
    "labels = df.Label\n",
    "##run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1df6fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "embedding_dim = 16\n",
    "max_length = 100\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<OOV>\"\n",
    "training_size = round(len(df)*0.8)\n",
    "##run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c84adbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sentences = sentences[0:training_size]\n",
    "testing_sentences = sentences[training_size:]\n",
    "training_labels = labels[0:training_size]\n",
    "testing_labels = labels[training_size:]\n",
    "##run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65d60b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(training_sentences)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
    "training_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
    "testing_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "##run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3825c0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "training_padded = np.array(training_padded)\n",
    "training_labels = np.array(training_labels)\n",
    "testing_padded = np.array(testing_padded)\n",
    "testing_labels = np.array(testing_labels)\n",
    "\n",
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f532f609",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(24, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0e419b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 16)           160000    \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 16)               0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 24)                408       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 25        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 160,433\n",
      "Trainable params: 160,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa58fb28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "69/69 - 1s - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6934 - val_accuracy: 0.4782 - 829ms/epoch - 12ms/step\n",
      "Epoch 2/30\n",
      "69/69 - 0s - loss: 0.6919 - accuracy: 0.5109 - val_loss: 0.6927 - val_accuracy: 0.4782 - 169ms/epoch - 2ms/step\n",
      "Epoch 3/30\n",
      "69/69 - 0s - loss: 0.6888 - accuracy: 0.5414 - val_loss: 0.6898 - val_accuracy: 0.4800 - 148ms/epoch - 2ms/step\n",
      "Epoch 4/30\n",
      "69/69 - 0s - loss: 0.6797 - accuracy: 0.6160 - val_loss: 0.6824 - val_accuracy: 0.5418 - 195ms/epoch - 3ms/step\n",
      "Epoch 5/30\n",
      "69/69 - 0s - loss: 0.6579 - accuracy: 0.7225 - val_loss: 0.6659 - val_accuracy: 0.6091 - 138ms/epoch - 2ms/step\n",
      "Epoch 6/30\n",
      "69/69 - 0s - loss: 0.6172 - accuracy: 0.8062 - val_loss: 0.6415 - val_accuracy: 0.6218 - 145ms/epoch - 2ms/step\n",
      "Epoch 7/30\n",
      "69/69 - 0s - loss: 0.5587 - accuracy: 0.8535 - val_loss: 0.5972 - val_accuracy: 0.7709 - 165ms/epoch - 2ms/step\n",
      "Epoch 8/30\n",
      "69/69 - 0s - loss: 0.4919 - accuracy: 0.8649 - val_loss: 0.5636 - val_accuracy: 0.7655 - 161ms/epoch - 2ms/step\n",
      "Epoch 9/30\n",
      "69/69 - 0s - loss: 0.4249 - accuracy: 0.9026 - val_loss: 0.5288 - val_accuracy: 0.7945 - 162ms/epoch - 2ms/step\n",
      "Epoch 10/30\n",
      "69/69 - 0s - loss: 0.3652 - accuracy: 0.9236 - val_loss: 0.5014 - val_accuracy: 0.8018 - 132ms/epoch - 2ms/step\n",
      "Epoch 11/30\n",
      "69/69 - 0s - loss: 0.3186 - accuracy: 0.9359 - val_loss: 0.4834 - val_accuracy: 0.7945 - 155ms/epoch - 2ms/step\n",
      "Epoch 12/30\n",
      "69/69 - 0s - loss: 0.2785 - accuracy: 0.9422 - val_loss: 0.4712 - val_accuracy: 0.7927 - 187ms/epoch - 3ms/step\n",
      "Epoch 13/30\n",
      "69/69 - 0s - loss: 0.2449 - accuracy: 0.9472 - val_loss: 0.4564 - val_accuracy: 0.8109 - 204ms/epoch - 3ms/step\n",
      "Epoch 14/30\n",
      "69/69 - 0s - loss: 0.2147 - accuracy: 0.9577 - val_loss: 0.4567 - val_accuracy: 0.7982 - 151ms/epoch - 2ms/step\n",
      "Epoch 15/30\n",
      "69/69 - 0s - loss: 0.1951 - accuracy: 0.9613 - val_loss: 0.4422 - val_accuracy: 0.8091 - 148ms/epoch - 2ms/step\n",
      "Epoch 16/30\n",
      "69/69 - 0s - loss: 0.1736 - accuracy: 0.9631 - val_loss: 0.4402 - val_accuracy: 0.8055 - 143ms/epoch - 2ms/step\n",
      "Epoch 17/30\n",
      "69/69 - 0s - loss: 0.1578 - accuracy: 0.9668 - val_loss: 0.4476 - val_accuracy: 0.8018 - 151ms/epoch - 2ms/step\n",
      "Epoch 18/30\n",
      "69/69 - 0s - loss: 0.1468 - accuracy: 0.9668 - val_loss: 0.4362 - val_accuracy: 0.8109 - 145ms/epoch - 2ms/step\n",
      "Epoch 19/30\n",
      "69/69 - 0s - loss: 0.1330 - accuracy: 0.9709 - val_loss: 0.4493 - val_accuracy: 0.7982 - 148ms/epoch - 2ms/step\n",
      "Epoch 20/30\n",
      "69/69 - 0s - loss: 0.1189 - accuracy: 0.9763 - val_loss: 0.4445 - val_accuracy: 0.8055 - 140ms/epoch - 2ms/step\n",
      "Epoch 21/30\n",
      "69/69 - 0s - loss: 0.1116 - accuracy: 0.9782 - val_loss: 0.4389 - val_accuracy: 0.8055 - 130ms/epoch - 2ms/step\n",
      "Epoch 22/30\n",
      "69/69 - 0s - loss: 0.1009 - accuracy: 0.9804 - val_loss: 0.4413 - val_accuracy: 0.8055 - 131ms/epoch - 2ms/step\n",
      "Epoch 23/30\n",
      "69/69 - 0s - loss: 0.0937 - accuracy: 0.9818 - val_loss: 0.4451 - val_accuracy: 0.8073 - 133ms/epoch - 2ms/step\n",
      "Epoch 24/30\n",
      "69/69 - 0s - loss: 0.0883 - accuracy: 0.9841 - val_loss: 0.4542 - val_accuracy: 0.8000 - 132ms/epoch - 2ms/step\n",
      "Epoch 25/30\n",
      "69/69 - 0s - loss: 0.0810 - accuracy: 0.9836 - val_loss: 0.4510 - val_accuracy: 0.8018 - 136ms/epoch - 2ms/step\n",
      "Epoch 26/30\n",
      "69/69 - 0s - loss: 0.0769 - accuracy: 0.9836 - val_loss: 0.4561 - val_accuracy: 0.8091 - 131ms/epoch - 2ms/step\n",
      "Epoch 27/30\n",
      "69/69 - 0s - loss: 0.0692 - accuracy: 0.9891 - val_loss: 0.4586 - val_accuracy: 0.8055 - 132ms/epoch - 2ms/step\n",
      "Epoch 28/30\n",
      "69/69 - 0s - loss: 0.0658 - accuracy: 0.9882 - val_loss: 0.4673 - val_accuracy: 0.8073 - 135ms/epoch - 2ms/step\n",
      "Epoch 29/30\n",
      "69/69 - 0s - loss: 0.0625 - accuracy: 0.9895 - val_loss: 0.4694 - val_accuracy: 0.8073 - 148ms/epoch - 2ms/step\n",
      "Epoch 30/30\n",
      "69/69 - 0s - loss: 0.0586 - accuracy: 0.9891 - val_loss: 0.4768 - val_accuracy: 0.8018 - 135ms/epoch - 2ms/step\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "history = model.fit(training_padded, training_labels, epochs=num_epochs, validation_data=(testing_padded, testing_labels), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acc9d241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16)\n"
     ]
    }
   ],
   "source": [
    "e = model.layers[0]\n",
    "weights = e.get_weights()[0]\n",
    "print(weights.shape) # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c3403f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 83ms/step\n",
      "[[0.9403698]]\n"
     ]
    }
   ],
   "source": [
    "sentence = [\"it is very good\"]\n",
    "sequences = tokenizer.texts_to_sequences(sentence)\n",
    "padded = pad_sequences(sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "print(model.predict(padded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bfe1491b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(r'Model/my_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c479b85a",
   "metadata": {},
   "source": [
    "# Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc81cb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model(r'Model/my_model.h5')\n",
    "##run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "339d594a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "It was not amusing\n",
      "negative\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "it is not complete\n",
      "negative\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "it needs some more refining\n",
      "negative\n"
     ]
    }
   ],
   "source": [
    "sentence = [\"It was not amusing\",\"it is not complete\",\"it needs some more refining\"]\n",
    "sequences = tokenizer.texts_to_sequences(sentence)\n",
    "padded = pad_sequences(sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "x = 0\n",
    "size = len(padded)\n",
    "\n",
    "while True:\n",
    "  y = model.predict(padded)[x]\n",
    "  z = (sentence)[x]\n",
    "  x = x+1 \n",
    "  \n",
    "  if(y>0.5):\n",
    "    print(z)\n",
    "    print(\"positive\")\n",
    "  else:\n",
    "    print(z)\n",
    "    print(\"negative\")\n",
    "\n",
    "  if(x==size):\n",
    "    break\n",
    "##run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d38f6b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "from __future__ import unicode_literals, print_function\n",
    "from prompt_toolkit import print_formatted_text, HTML\n",
    "#run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cb6c6400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2ad3006204e410e901a498faf16d635",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(HTML(value='<h1>NLP Sentiment Detection</h1>'), HTML(value='<h2>Sentece</h2>'), â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sentence\n",
    "\n",
    "sentence_process = widgets.Text(placeholder='Your sentence here')\n",
    "\n",
    "\n",
    "# button \n",
    "\n",
    "button_send = widgets.Button(\n",
    "                description='Process',\n",
    "                tooltip='Send',\n",
    "                style={'description_width': 'initial'}\n",
    "            )\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "def on_button_clicked1(event):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        sente = sentence_process.value\n",
    "        sentence = [sente]\n",
    "        sequences = tokenizer.texts_to_sequences(sentence)\n",
    "        padded = pad_sequences(sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "        x = 0\n",
    "        size = len(padded)\n",
    "\n",
    "        while True:\n",
    "          y = model.predict(padded)[x]\n",
    "          z = (sentence)[x]\n",
    "          x = x+1 \n",
    "          \n",
    "          if(y>0.5):\n",
    "            print(\"\")\n",
    "            print(z)\n",
    "            print('\\033[1m' + 'Positive' + '\\033[0m')\n",
    "          else:\n",
    "            print(\"\")\n",
    "            print(z)\n",
    "            print('\\033[1m' + 'Negaive' + '\\033[0m')\n",
    "            \n",
    "          if(x==size):\n",
    "            break\n",
    "\n",
    "button_send.on_click(on_button_clicked1)\n",
    "\n",
    "vbox_result = widgets.VBox([button_send, output])\n",
    "# stacked right hand side\n",
    "\n",
    "text_0 = widgets.HTML(value=\"<h1>NLP Sentiment Detection</h1>\")\n",
    "text_1 = widgets.HTML(value=\"<h2>Sentece</h2>\")\n",
    "\n",
    "vbox_text = widgets.VBox([text_0, text_1, sentence_process, vbox_result])\n",
    "page = widgets.HBox([vbox_text])\n",
    "display(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d5b1fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5764de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: ok\n",
      "Enabling: voila\n",
      "- Writing config: F:\\Anaconda\\envs\\nlp\\etc\\jupyter\n",
      "    - Validating...\n",
      "      voila 0.3.5 ok\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbextension enable --py widgetsnbextension --sys-prefix\n",
    "!jupyter serverextension enable voila --sys-prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cc886886",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee0db72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
